{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy and Persistent Homology\n",
    "\n",
    "## &copy;  [Omkar Mehta](omehta2@illinois.edu) ##\n",
    "### Industrial and Enterprise Systems Engineering, The Grainger College of Engineering,  UIUC ###\n",
    "\n",
    "<hr style=\"border:2px solid blue\"> </hr>\n",
    "\n",
    "# [Reference](https://towardsdatascience.com/how-to-pull-data-from-an-api-using-python-requests-edcc8d6441b1)\n",
    "\n",
    "# Part 1: Download Data from INaturalist website using API\n",
    "From API documentation,we get the following information:\n",
    "\n",
    "`Please note that we throttle API usage to a max of 100 requests per minute, though we ask that you try to keep it to 60 requests per minute or lower, and to keep under 10,000 requests per day. If we notice usage that has serious impact on our performance we may institute blocks without notification.`\n",
    "\n",
    "`per_page\n",
    "Allowed values: 1 to 200`\n",
    "\n",
    "Locations data collected from:\n",
    "* place_id: 1563\n",
    "* place_id: 49906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import requests\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for storing all the pulled data\n",
    "data = {\n",
    "    'time_observed_at': list(),\n",
    "    'species_guess': list(),\n",
    "    'genus_name': list(),\n",
    "    'rank': list(),\n",
    "    'wikipedia_url': list(),\n",
    "    'iconic_taxon_name': list(),\n",
    "    'preferred_common_name': list(),\n",
    "    'uri': list(),\n",
    "    'longitude': list(),\n",
    "    'latitude': list(),\n",
    "    'place_guess': list()\n",
    "}"
   ]
  },
  {
   "source": [
    "## Part 1.1. Function for getting the dictionary of pages and page_numbers\n",
    "\n",
    "For each page, there is a different per_page limit. This was not mentioned in the api documentation of the inaturalist website."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages = {}\n",
    "# place_id = 1563\n",
    "# page_number = 1\n",
    "# per_page = 200 #max_limit\n",
    "# i = 1\n",
    "# sleep_time = 60\n",
    "# while True:\n",
    "#   while per_page != 0:\n",
    "#     #go through each page and per_page, get the request's response, if it is 200, append page_number:per_page to the dictionary.\n",
    "#     #if for any per_page, we get status_code != 200, we decrement the per_page by 1, and check response. \n",
    "    \n",
    "#     response = requests.get(\"https://api.inaturalist.org/v1/observations?place_id={}&page={}&per_page={}\".format(place_id, page_number, per_page))\n",
    "#     if i%50 == 0: #We have a limit of 60 pages per minute, for pulling data from API\n",
    "#         time.sleep(sleep_time)\n",
    "#     if response.status_code == 200:\n",
    "#       pages[page_number] = per_page\n",
    "#       page_number +=1\n",
    "#     elif response.status_code != 200:\n",
    "#       per_page -= 1\n",
    "#     i += 1\n",
    "#   break \n",
    "\n",
    "def findPerPage(place_id, page_number, per_page, how_many_pages):\n",
    "    pages = {}\n",
    "    i = 1\n",
    "    sleep_time = 60\n",
    "    while True:\n",
    "        while per_page != 0:\n",
    "            #go through each page and per_page, get the request's response, \n",
    "            # if it is 200, append page_number:per_page to the dictionary.\n",
    "            # if for any per_page, we get status_code != 200, we decrement the per_page by 1, and check response. \n",
    "            response = requests.get(\"https://api.inaturalist.org/v1/observations?place_id={}&page={}&per_page={}\".format(place_id, page_number, per_page))\n",
    "            if i%50 == 0: #We have a limit of 60 pages per minute, for pulling data from API\n",
    "                time.sleep(sleep_time)\n",
    "            if response.status_code == 200:\n",
    "                pages[page_number] = per_page\n",
    "                page_number +=1\n",
    "            elif response.status_code != 200:\n",
    "                per_page -= 1\n",
    "            i += 1\n",
    "\n",
    "            # if how_many_pages >= 200:\n",
    "            #     return pages\n",
    "        break\n",
    "    return pages\n",
    "\n",
    "def download_csv_pages(pages):\n",
    "    pages_Series = pd.Series(pages)\n",
    "    #pages_Series.to_csv('pages.csv')\n",
    "    pages_df = pd.DataFrame(pages_Series, columns=['page_number', 'per_page'])\n",
    "    pages_df.to_csv('pages.csv')\n",
    "\n",
    "def download_pickle_pages(pages):\n",
    "    pages_Series = pd.Series(pages)\n",
    "    #pages_Series.to_csv('pages.csv')\n",
    "    pages_df = pd.DataFrame(pages_Series, columns=['page_number', 'per_page'])\n",
    "    pages_df.to_pickle('pages.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages_Series = pd.Series(pages)\n",
    "# pages_Series.to_csv('pages.csv')\n",
    "# pages_df = pd.read_csv('pages.csv', names=['page_number', 'per_page'])\n",
    "# pages_df.info()\n",
    "# pages_df.to_csv('pages.csv')\n",
    "# pages_df.to_pickle('pages.pkl')"
   ]
  },
  {
   "source": [
    "## Part 1.2. Pull data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for pulling the data\n",
    "def pull_data(data, place_id, sleep_time, page_number, per_page):\n",
    "    '''\n",
    "    place_id: each location has a place_id, which we can get from the website\n",
    "    sleep_time: time in seconds we want to sleep\n",
    "    page_number: depends on the number of observations. total_observations/per_page\n",
    "    per_page: #observations per page\n",
    "    '''\n",
    "    if page_number%40 == 0:\n",
    "        time.sleep(sleep_time)\n",
    "    else:\n",
    "        response = requests.get(\"https://api.inaturalist.org/v1/observations?place_id={}&page={}&per_page={}\".format(place_id, page_number, per_page))\n",
    "        file_dict = response.json()\n",
    "        if ('results' in file_dict):\n",
    "            for j in range(per_page):\n",
    "            \n",
    "                if 'time_observed_at' in file_dict['results'][j]:\n",
    "                    data['time_observed_at'].append(file_dict['results'][j]['time_observed_at'])\n",
    "                else:\n",
    "                    data['time_observed_at'].append(None)\n",
    "                if 'species_guess' in file_dict['results'][j]:\n",
    "                    data['species_guess'].append(file_dict['results'][j]['species_guess'])\n",
    "                else:\n",
    "                    data['species_guess'].append(None)\n",
    "\n",
    "                if ('taxon' in file_dict['results'][j]) & (file_dict['results'][j]['taxon'] is not None) :\n",
    "                    #print(j)\n",
    "                    if 'name' in file_dict['results'][j]['taxon']:\n",
    "                        data['genus_name'].append(file_dict['results'][j]['taxon']['name'])\n",
    "                    else:\n",
    "                        data['genus_name'].append(None)\n",
    "                    if 'rank' in file_dict['results'][j]['taxon']:\n",
    "                        data['rank'].append(file_dict['results'][j]['taxon']['rank'])\n",
    "                    else:\n",
    "                        data['rank'].append(None)\n",
    "                    if 'wikipedia_url' in file_dict['results'][j]['taxon']:\n",
    "                        data['wikipedia_url'].append(file_dict['results'][j]['taxon']['wikipedia_url'])\n",
    "                    else:\n",
    "                        data['wikipedia_url'].append(None)\n",
    "                    if 'iconic_taxon_name' in file_dict['results'][j]['taxon']:\n",
    "                        data['iconic_taxon_name'].append(file_dict['results'][j]['taxon']['iconic_taxon_name'])\n",
    "                    else:\n",
    "                        data['iconic_taxon_name'].append(None)\n",
    "                    #print(j)\n",
    "                    if 'preferred_common_name' in file_dict['results'][j]['taxon']:\n",
    "                        data['preferred_common_name'].append(file_dict['results'][j]['taxon']['preferred_common_name'])\n",
    "                    else:\n",
    "                        data['preferred_common_name'].append(None)\n",
    "                else:\n",
    "                    data['genus_name'].append(None)\n",
    "                    data['rank'].append(None)\n",
    "                    data['wikipedia_url'].append(None)\n",
    "                    data['iconic_taxon_name'].append(None)\n",
    "                    data['preferred_common_name'].append(None)\n",
    "                if 'uri' in file_dict['results'][j]:\n",
    "                    data['uri'].append(file_dict['results'][j]['uri'])\n",
    "                else:\n",
    "                    data['uri'].append(None)\n",
    "                if 'geojson' in file_dict['results'][j]:\n",
    "                    data['longitude'].append(file_dict['results'][j]['geojson']['coordinates'][0])\n",
    "                    data['latitude'].append(file_dict['results'][j]['geojson']['coordinates'][1])\n",
    "                else:\n",
    "                    data['longitude'].append(None)\n",
    "                    data['latitude'].append(None)\n",
    "                if 'place_guess' in file_dict['results'][j]:\n",
    "                    data['place_guess'].append(file_dict['results'][j]['place_guess'])\n",
    "                else:\n",
    "                    data['place_guess'].append(None)\n",
    "        else:\n",
    "            print(page_number)\n",
    "\n",
    "    "
   ]
  },
  {
   "source": [
    "`pages.csv' contains the \n",
    "```python\n",
    "{'page_number': 'per_page'}\n",
    "```\n",
    "dictionary. For each page, we have a maximum limit on the number of observations that one can pull."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = pd.read_csv('pages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for pulling data. Change place_id\n",
    "# for i in range(1, len(pages)):\n",
    "\n",
    "#     pull_data(data, 1563, 60, int(pages['page_number'][i]), int(pages['per_page'][i]))\n",
    "# data_df = pd.DataFrame(data)\n",
    "# data_df.info()\n",
    "\n",
    "# place_id = 1563\n",
    "# csv_file = 'data_' + str(place_id) + '_' + str(datetime.now().strftime('%Y_%m_%d_%H_%M_%S')) + '.csv'\n",
    "# pickle_file = 'data_' + str(place_id) + '_' + str(datetime.now().strftime('%Y_%m_%d_%H_%M_%S')) + '.pkl'\n",
    "# data_df.to_csv(csv_file)\n",
    "# data_df.to_pickle(pickle_file)\n",
    "# data_df.info()\n",
    "\n",
    "def getData(pages_df, data, place_id):\n",
    "\n",
    "    for i in range(1, len(pages)):\n",
    "        pull_data(data, place_id, 60, int(pages_df['page_number'][i]), int(pages_df['per_page'][i]))\n",
    "    data_df = pd.DataFrame(data)\n",
    "    return data_df\n",
    "def download_csv_data(data, place_id, ):\n",
    "\n",
    "    csv_file = 'data_' + str(place_id) + '_' + str(datetime.now().strftime('%Y_%m_%d_%H_%M_%S')) + '.csv'\n",
    "    pickle_file = 'data_' + str(place_id) + '_' + str(datetime.now().strftime('%Y_%m_%d_%H_%M_%S')) + '.pkl'\n",
    "    data_df.to_csv(csv_file)\n",
    "    data_df.to_pickle(pickle_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Use pickle instead of csv***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 45576 entries, 0 to 45575\nData columns (total 11 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   time_observed_at       45240 non-null  object \n 1   species_guess          31406 non-null  object \n 2   genus_name             44627 non-null  object \n 3   rank                   44627 non-null  object \n 4   wikipedia_url          42470 non-null  object \n 5   iconic_taxon_name      44611 non-null  object \n 6   preferred_common_name  42654 non-null  object \n 7   uri                    45576 non-null  object \n 8   longitude              45576 non-null  float64\n 9   latitude               45576 non-null  float64\n 10  place_guess            45576 non-null  object \ndtypes: float64(2), object(9)\nmemory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('data_1563_2021_06_24_12_57_28.csv', index_col= 0)\n",
    "# data_df.to_pickle('data_1563_2021_06_06_20_47_20.pickle')\n",
    "# data_df = pd.read_pickle('data_1563_2021_06_06_20_47_20.pickle')\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 42470 entries, 0 to 45575\nData columns (total 11 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   time_observed_at       42201 non-null  object \n 1   species_guess          29515 non-null  object \n 2   genus_name             42470 non-null  object \n 3   rank                   42470 non-null  object \n 4   wikipedia_url          42470 non-null  object \n 5   iconic_taxon_name      42454 non-null  object \n 6   preferred_common_name  41305 non-null  object \n 7   uri                    42470 non-null  object \n 8   longitude              42470 non-null  float64\n 9   latitude               42470 non-null  float64\n 10  place_guess            42470 non-null  object \ndtypes: float64(2), object(9)\nmemory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.dropna(subset = ['wikipedia_url'], inplace = True)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             time_observed_at        species_guess  \\\n",
       "0   2021-06-23T16:22:12-05:00                  NaN   \n",
       "1   2021-06-24T10:29:25-05:00                  NaN   \n",
       "2   2021-06-23T14:19:35-05:00                  NaN   \n",
       "3   2021-06-24T09:45:31+00:00                  NaN   \n",
       "4   2021-06-24T06:03:52-05:00   Eastern Box Turtle   \n",
       "5   2021-06-21T15:57:37-05:00                  NaN   \n",
       "6   2021-06-23T20:09:39+00:00  Xylotrechus colonus   \n",
       "7   2021-06-23T10:45:09-05:00       garden petunia   \n",
       "8   2021-06-23T11:00:59-05:00         Spiked Sedge   \n",
       "9   2021-06-23T10:36:28-05:00                 Dill   \n",
       "10  2021-06-23T13:28:46+00:00     Great Horned Owl   \n",
       "11  2021-06-23T09:24:31-10:00                  NaN   \n",
       "12  2021-06-23T09:42:15-10:00        Widow Skimmer   \n",
       "13  2021-06-23T16:41:32-05:00                  NaN   \n",
       "14  2021-06-23T09:24:06-10:00                  NaN   \n",
       "\n",
       "                     genus_name        rank  \\\n",
       "0               Storeria dekayi     species   \n",
       "1          Potentilla norvegica     species   \n",
       "2                 Tettigoniinae   subfamily   \n",
       "3              Marpissa lineata     species   \n",
       "4   Terrapene carolina carolina  subspecies   \n",
       "5           Aesculus parviflora     species   \n",
       "6           Xylotrechus colonus     species   \n",
       "7          Petunia × atkinsiana      hybrid   \n",
       "8                 Carex spicata     species   \n",
       "9            Anethum graveolens     species   \n",
       "10             Bubo virginianus     species   \n",
       "11          Bombus griseocollis     species   \n",
       "12           Libellula luctuosa     species   \n",
       "13                 Angiospermae   subphylum   \n",
       "14                Lucidota atra     species   \n",
       "\n",
       "                                        wikipedia_url iconic_taxon_name  \\\n",
       "0        http://en.wikipedia.org/wiki/Storeria_dekayi          Reptilia   \n",
       "1   http://en.wikipedia.org/wiki/Potentilla_norvegica           Plantae   \n",
       "2          http://en.wikipedia.org/wiki/Tettigoniinae           Insecta   \n",
       "3       http://en.wikipedia.org/wiki/Marpissa_lineata         Arachnida   \n",
       "4    https://en.wikipedia.org/wiki/Eastern_box_turtle          Reptilia   \n",
       "5    http://en.wikipedia.org/wiki/Aesculus_parviflora           Plantae   \n",
       "6    http://en.wikipedia.org/wiki/Xylotrechus_colonus           Insecta   \n",
       "7   http://en.wikipedia.org/wiki/Petunia_×_atkinsiana           Plantae   \n",
       "8          http://en.wikipedia.org/wiki/Carex_spicata           Plantae   \n",
       "9                   http://en.wikipedia.org/wiki/Dill           Plantae   \n",
       "10      http://en.wikipedia.org/wiki/Great_horned_owl              Aves   \n",
       "11   http://en.wikipedia.org/wiki/Bombus_griseocollis           Insecta   \n",
       "12         http://en.wikipedia.org/wiki/Widow_skimmer           Insecta   \n",
       "13      https://en.wikipedia.org/wiki/Flowering_plant           Plantae   \n",
       "14         http://en.wikipedia.org/wiki/Lucidota_atra           Insecta   \n",
       "\n",
       "                preferred_common_name  \\\n",
       "0                  Dekay's Brownsnake   \n",
       "1                    rough cinquefoil   \n",
       "2                 Shieldback Katydids   \n",
       "3   Four-lined Slender Jumping Spider   \n",
       "4                  Eastern Box Turtle   \n",
       "5                 bottlebrush buckeye   \n",
       "6                        Rustic Borer   \n",
       "7                      garden petunia   \n",
       "8                        Spiked Sedge   \n",
       "9                                Dill   \n",
       "10                   Great Horned Owl   \n",
       "11            Brown-belted Bumble Bee   \n",
       "12                      Widow Skimmer   \n",
       "13                   flowering plants   \n",
       "14                      Black Firefly   \n",
       "\n",
       "                                                  uri  longitude   latitude  \\\n",
       "0   https://www.inaturalist.org/observations/84313002 -88.367813  40.212863   \n",
       "1   https://www.inaturalist.org/observations/84311385 -88.369087  40.213030   \n",
       "2   https://www.inaturalist.org/observations/84311301 -88.368783  40.210567   \n",
       "3   https://www.inaturalist.org/observations/84306238 -88.208083  40.112786   \n",
       "4   https://www.inaturalist.org/observations/84287773 -88.164075  40.030186   \n",
       "5   https://www.inaturalist.org/observations/84273805 -88.204346  40.110535   \n",
       "6   https://www.inaturalist.org/observations/84257323 -88.185602  40.132840   \n",
       "7   https://www.inaturalist.org/observations/84252834 -88.255166  40.115403   \n",
       "8   https://www.inaturalist.org/observations/84252426 -88.267401  40.116266   \n",
       "9   https://www.inaturalist.org/observations/84252189 -88.246905  40.115404   \n",
       "10  https://www.inaturalist.org/observations/84240421 -88.213157  40.106400   \n",
       "11  https://www.inaturalist.org/observations/84232835 -87.988695  40.074878   \n",
       "12  https://www.inaturalist.org/observations/84232687 -87.988695  40.074878   \n",
       "13  https://www.inaturalist.org/observations/84232238 -88.205561  40.080461   \n",
       "14  https://www.inaturalist.org/observations/84232221 -87.988700  40.074811   \n",
       "\n",
       "                                  place_guess  \n",
       "0                             Mahomet, IL, US  \n",
       "1     N Lake of the Woods Rd, Mahomet, IL, US  \n",
       "2                             Mahomet, IL, US  \n",
       "3                   W Main St, Urbana, IL, US  \n",
       "4                                Illinois, US  \n",
       "5                                      Urbana  \n",
       "6                Hamilton Ave, Urbana, IL, US  \n",
       "7         W University Ave, Champaign, IL, US  \n",
       "8             S Russell St, Champaign, IL, US  \n",
       "9               S State St, Champaign, IL, US  \n",
       "10            S McCullough St, Urbana, IL, US  \n",
       "11  Homer Lake Forest Preserve, Ogden, IL, US  \n",
       "12  Homer Lake Forest Preserve, Ogden, IL, US  \n",
       "13                            Urbana, IL, USA  \n",
       "14  Homer Lake Forest Preserve, Ogden, IL, US  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_observed_at</th>\n      <th>species_guess</th>\n      <th>genus_name</th>\n      <th>rank</th>\n      <th>wikipedia_url</th>\n      <th>iconic_taxon_name</th>\n      <th>preferred_common_name</th>\n      <th>uri</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>place_guess</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-06-23T16:22:12-05:00</td>\n      <td>NaN</td>\n      <td>Storeria dekayi</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Storeria_dekayi</td>\n      <td>Reptilia</td>\n      <td>Dekay's Brownsnake</td>\n      <td>https://www.inaturalist.org/observations/84313002</td>\n      <td>-88.367813</td>\n      <td>40.212863</td>\n      <td>Mahomet, IL, US</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-06-24T10:29:25-05:00</td>\n      <td>NaN</td>\n      <td>Potentilla norvegica</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Potentilla_norvegica</td>\n      <td>Plantae</td>\n      <td>rough cinquefoil</td>\n      <td>https://www.inaturalist.org/observations/84311385</td>\n      <td>-88.369087</td>\n      <td>40.213030</td>\n      <td>N Lake of the Woods Rd, Mahomet, IL, US</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-06-23T14:19:35-05:00</td>\n      <td>NaN</td>\n      <td>Tettigoniinae</td>\n      <td>subfamily</td>\n      <td>http://en.wikipedia.org/wiki/Tettigoniinae</td>\n      <td>Insecta</td>\n      <td>Shieldback Katydids</td>\n      <td>https://www.inaturalist.org/observations/84311301</td>\n      <td>-88.368783</td>\n      <td>40.210567</td>\n      <td>Mahomet, IL, US</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-06-24T09:45:31+00:00</td>\n      <td>NaN</td>\n      <td>Marpissa lineata</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Marpissa_lineata</td>\n      <td>Arachnida</td>\n      <td>Four-lined Slender Jumping Spider</td>\n      <td>https://www.inaturalist.org/observations/84306238</td>\n      <td>-88.208083</td>\n      <td>40.112786</td>\n      <td>W Main St, Urbana, IL, US</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-06-24T06:03:52-05:00</td>\n      <td>Eastern Box Turtle</td>\n      <td>Terrapene carolina carolina</td>\n      <td>subspecies</td>\n      <td>https://en.wikipedia.org/wiki/Eastern_box_turtle</td>\n      <td>Reptilia</td>\n      <td>Eastern Box Turtle</td>\n      <td>https://www.inaturalist.org/observations/84287773</td>\n      <td>-88.164075</td>\n      <td>40.030186</td>\n      <td>Illinois, US</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2021-06-21T15:57:37-05:00</td>\n      <td>NaN</td>\n      <td>Aesculus parviflora</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Aesculus_parviflora</td>\n      <td>Plantae</td>\n      <td>bottlebrush buckeye</td>\n      <td>https://www.inaturalist.org/observations/84273805</td>\n      <td>-88.204346</td>\n      <td>40.110535</td>\n      <td>Urbana</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2021-06-23T20:09:39+00:00</td>\n      <td>Xylotrechus colonus</td>\n      <td>Xylotrechus colonus</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Xylotrechus_colonus</td>\n      <td>Insecta</td>\n      <td>Rustic Borer</td>\n      <td>https://www.inaturalist.org/observations/84257323</td>\n      <td>-88.185602</td>\n      <td>40.132840</td>\n      <td>Hamilton Ave, Urbana, IL, US</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2021-06-23T10:45:09-05:00</td>\n      <td>garden petunia</td>\n      <td>Petunia × atkinsiana</td>\n      <td>hybrid</td>\n      <td>http://en.wikipedia.org/wiki/Petunia_×_atkinsiana</td>\n      <td>Plantae</td>\n      <td>garden petunia</td>\n      <td>https://www.inaturalist.org/observations/84252834</td>\n      <td>-88.255166</td>\n      <td>40.115403</td>\n      <td>W University Ave, Champaign, IL, US</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2021-06-23T11:00:59-05:00</td>\n      <td>Spiked Sedge</td>\n      <td>Carex spicata</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Carex_spicata</td>\n      <td>Plantae</td>\n      <td>Spiked Sedge</td>\n      <td>https://www.inaturalist.org/observations/84252426</td>\n      <td>-88.267401</td>\n      <td>40.116266</td>\n      <td>S Russell St, Champaign, IL, US</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2021-06-23T10:36:28-05:00</td>\n      <td>Dill</td>\n      <td>Anethum graveolens</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Dill</td>\n      <td>Plantae</td>\n      <td>Dill</td>\n      <td>https://www.inaturalist.org/observations/84252189</td>\n      <td>-88.246905</td>\n      <td>40.115404</td>\n      <td>S State St, Champaign, IL, US</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2021-06-23T13:28:46+00:00</td>\n      <td>Great Horned Owl</td>\n      <td>Bubo virginianus</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Great_horned_owl</td>\n      <td>Aves</td>\n      <td>Great Horned Owl</td>\n      <td>https://www.inaturalist.org/observations/84240421</td>\n      <td>-88.213157</td>\n      <td>40.106400</td>\n      <td>S McCullough St, Urbana, IL, US</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2021-06-23T09:24:31-10:00</td>\n      <td>NaN</td>\n      <td>Bombus griseocollis</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Bombus_griseocollis</td>\n      <td>Insecta</td>\n      <td>Brown-belted Bumble Bee</td>\n      <td>https://www.inaturalist.org/observations/84232835</td>\n      <td>-87.988695</td>\n      <td>40.074878</td>\n      <td>Homer Lake Forest Preserve, Ogden, IL, US</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2021-06-23T09:42:15-10:00</td>\n      <td>Widow Skimmer</td>\n      <td>Libellula luctuosa</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Widow_skimmer</td>\n      <td>Insecta</td>\n      <td>Widow Skimmer</td>\n      <td>https://www.inaturalist.org/observations/84232687</td>\n      <td>-87.988695</td>\n      <td>40.074878</td>\n      <td>Homer Lake Forest Preserve, Ogden, IL, US</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2021-06-23T16:41:32-05:00</td>\n      <td>NaN</td>\n      <td>Angiospermae</td>\n      <td>subphylum</td>\n      <td>https://en.wikipedia.org/wiki/Flowering_plant</td>\n      <td>Plantae</td>\n      <td>flowering plants</td>\n      <td>https://www.inaturalist.org/observations/84232238</td>\n      <td>-88.205561</td>\n      <td>40.080461</td>\n      <td>Urbana, IL, USA</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2021-06-23T09:24:06-10:00</td>\n      <td>NaN</td>\n      <td>Lucidota atra</td>\n      <td>species</td>\n      <td>http://en.wikipedia.org/wiki/Lucidota_atra</td>\n      <td>Insecta</td>\n      <td>Black Firefly</td>\n      <td>https://www.inaturalist.org/observations/84232221</td>\n      <td>-87.988700</td>\n      <td>40.074811</td>\n      <td>Homer Lake Forest Preserve, Ogden, IL, US</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "data_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Get taxonomy data from the rows\n",
    "\n",
    "## Search for a term in wikipedia search and get its page\n",
    "\n",
    "Uncomment for looking at results. I didn't find it useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wikipedia\n",
    "# result = wikipedia.search(\"Monarda_fistulosa\")\n",
    "# print(result)\n",
    "# # get the page: Neural network\n",
    "# page = wikipedia.page(result[0])\n",
    "# print(page)\n",
    "# # get the title of the page\n",
    "# title = page.title\n",
    "# print(title)\n",
    "# # get the categories of the page\n",
    "# categories = page.categories\n",
    "# print(categories)\n",
    "# # get the whole wikipedia page text (content)\n",
    "# content = page.content\n",
    "# print(content)\n",
    "# # get all the links in the page\n",
    "# links = page.links\n",
    "# print(links)\n",
    "# # get the page references\n",
    "# references = page.references\n",
    "# print(references)\n",
    "# # summary\n",
    "# summary = page.summary\n",
    "# print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1. Scraping data using beautiful soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row, if wikipedia_uri exists, we will use beautiful soup to extract the data \n",
    "# related to taxonomy\n",
    "# import required modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# get URL\n",
    "page = requests.get(\"http://en.wikipedia.org/wiki/Monarda_fistulosa\")\n",
    "  \n",
    "# display status code\n",
    "# print(page.status_code)\n",
    "  \n",
    "# display scrapped data\n",
    "# print(page.content)\n",
    "\n",
    "# scrape webpage\n",
    "soup = BeautifulSoup(page.content, 'html.parser') #.get_text(strip=True) #This removes \\xa0\n",
    "\n",
    "# display scrapped data\n",
    "# print(soup.prettify())\n",
    "\n",
    "# list(soup.children)\n",
    "\n",
    "# find all occurance of p in HTML\n",
    "# includes HTML tags\n",
    "# print(soup.find_all('p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'http://en.wikipedia.org/wiki/Aesculus_parviflora'"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "data_df[data_df['rank'] == 'species' ]['wikipedia_url'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1.1. Get table from the id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['Kingdom', 'Plantae'],\n",
       " ['Order', 'Lamiales'],\n",
       " ['Family', 'Lamiaceae'],\n",
       " ['Genus', 'Monarda'],\n",
       " ['Species', 'M. fistulosa']]"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "# create object\n",
    "# object = soup.find(id=\"mw-content-text\")\n",
    "\n",
    "# # find tags\n",
    "# items = object.find_all(class_=\"infobox biota\")\n",
    "# result = items[0]\n",
    "  \n",
    "# # display tags\n",
    "# print(result.prettify())\n",
    "\n",
    "table = soup.find_all('table')\n",
    "\n",
    "# table[0]\n",
    "\n",
    "# for child in soup.find_all('table')[0].children:\n",
    "#     for td in child:\n",
    "#         print(td)\n",
    "\n",
    "# list(soup.find_all('table')[0].tr.next_siblings)\n",
    "\n",
    "# for sibling in soup.find_all('table')[0].tr.next_siblings:\n",
    "#     for td in sibling:\n",
    "#         print(td)\n",
    "\n",
    "table = soup.find('table', attrs={'class':'infobox biota'}) #class=\"infobox biota\"\n",
    "table_rows = table.find_all('tr')\n",
    "\n",
    "# table_rows\n",
    "\n",
    "# len(table_rows)\n",
    "data_taxonomy = {\n",
    "    'Kingdom': list(),\n",
    "    'Phylum': list(),\n",
    "    'Class': list(),\n",
    "    'Order': list(),\n",
    "    'Suborder': list(),\n",
    "    'Family': list(),\n",
    "    'Genus': list(),\n",
    "    'Species': list()\n",
    "}\n",
    "l = []\n",
    "data_taxonomy['Kingdom'].insert(0, None)\n",
    "data_taxonomy['Phylum'].insert(0, None)\n",
    "data_taxonomy['Class'].insert(0, None)\n",
    "data_taxonomy['Order'].insert(0, None)\n",
    "data_taxonomy['Suborder'].insert(0, None)\n",
    "data_taxonomy['Family'].insert(0, None)\n",
    "data_taxonomy['Genus'].insert(0, None)\n",
    "data_taxonomy['Species'].insert(0, None)\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text.replace('\\n', '').replace(':', '').replace(u'\\xa0', ' ') for tr in td]\n",
    "    \n",
    "\n",
    "    if 'Kingdom' in row:\n",
    "        data_taxonomy['Kingdom'][0] = row[1]\n",
    "        l.append(row)\n",
    "    if 'Phylum' in row:\n",
    "        data_taxonomy['Phylum'][0] = row[1]\n",
    "        l.append(row)   \n",
    "    if 'Class' in row:\n",
    "        data_taxonomy['Class'][0] = row[1]\n",
    "        l.append(row)\n",
    "    if 'Order' in row:\n",
    "        data_taxonomy['Order'][0] = row[1]\n",
    "        l.append(row)\n",
    "    if 'Suborder' in row:\n",
    "        data_taxonomy['Suborder'][0] = row[1]\n",
    "        l.append(row)\n",
    "    if 'Family' in row:\n",
    "        data_taxonomy['Family'][0] = row[1]\n",
    "        l.append(row)\n",
    "    if 'Genus' in row:\n",
    "        data_taxonomy['Genus'][0] = row[1]\n",
    "        l.append(row)\n",
    "    if 'Species' in row:\n",
    "        data_taxonomy['Species'][0] = row[1]\n",
    "        l.append(row)\n",
    "    \n",
    "    # elif 'Clade' in row:\n",
    "    #     l.append(row)\n",
    "l\n",
    "\n",
    "# 'Kingdom' in l[4]\n",
    "\n",
    "# table_rows = table_rows[4:13]\n",
    "\n",
    "# l = []\n",
    "# for tr in table_rows:\n",
    "#     td = tr.find_all('td')\n",
    "#     row = [tr.text for tr in td]\n",
    "#     l.append(row)\n",
    "\n",
    "# l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Kingdom': ['Plantae'],\n",
       " 'Phylum': [None],\n",
       " 'Class': [None],\n",
       " 'Order': ['Lamiales'],\n",
       " 'Suborder': [None],\n",
       " 'Family': ['Lamiaceae'],\n",
       " 'Genus': ['Monarda'],\n",
       " 'Species': ['M. fistulosa']}"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "data_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "42470"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    666\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 54] Connection reset by peer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    720\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    666\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-cb2dd12a3266>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdata_taxonomy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Species'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wikipedia_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# scrape webpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))"
     ]
    }
   ],
   "source": [
    "data_taxonomy = {\n",
    "    'Kingdom': list(),\n",
    "    'Phylum': list(),\n",
    "    'Class': list(),\n",
    "    'Order': list(),\n",
    "    'Suborder': list(),\n",
    "    'Family': list(),\n",
    "    'Genus': list(),\n",
    "    'Species': list()\n",
    "}\n",
    "for i in range(len(data_df)):\n",
    "    if 'http' in data_df['wikipedia_url'][i]:\n",
    "        #print(i)\n",
    "        # get URL\n",
    "        data_taxonomy['Kingdom'].insert(i, None)\n",
    "        data_taxonomy['Phylum'].insert(i, None)\n",
    "        data_taxonomy['Class'].insert(i, None)\n",
    "        data_taxonomy['Order'].insert(i, None)\n",
    "        data_taxonomy['Suborder'].insert(i, None)\n",
    "        data_taxonomy['Family'].insert(i, None)\n",
    "        data_taxonomy['Genus'].insert(i, None)\n",
    "        data_taxonomy['Species'].insert(i, None)\n",
    "\n",
    "        page = requests.get(data_df['wikipedia_url'][i])\n",
    "\n",
    "        # scrape webpage\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        #table = soup.find_all('table')\n",
    "\n",
    "        table = soup.find('table', attrs={'class':'infobox biota'}) #class=\"infobox biota\"\n",
    "        if table is not None:\n",
    "        \n",
    "        \n",
    "            table_rows = table.find_all('tr')\n",
    "            for tr in table_rows:\n",
    "                td = tr.find_all('td')\n",
    "                row = [tr.text.replace('\\n', '').replace(':', '').replace(u'\\xa0', ' ') for tr in td]\n",
    "        \n",
    "\n",
    "                if 'Kingdom' in row:\n",
    "                    data_taxonomy['Kingdom'][i] = row[1]\n",
    "                    #l.append(row)\n",
    "                if 'Phylum' in row:\n",
    "                    data_taxonomy['Phylum'][i] = row[1]\n",
    "                    #l.append(row)   \n",
    "                if 'Class' in row:\n",
    "                    data_taxonomy['Class'][i] = row[1]\n",
    "                    #l.append(row)\n",
    "                if 'Order' in row:\n",
    "                    data_taxonomy['Order'][i] = row[1]\n",
    "                    #l.append(row)\n",
    "                if 'Suborder' in row:\n",
    "                    data_taxonomy['Suborder'][i] = row[1]\n",
    "                    #l.append(row)\n",
    "                if 'Family' in row:\n",
    "                    data_taxonomy['Family'][i] = row[1]\n",
    "                    #l.append(row)\n",
    "                if 'Genus' in row:\n",
    "                    data_taxonomy['Genus'][i] = row[1]\n",
    "                    #l.append(row)\n",
    "                if 'Species' in row:\n",
    "                    data_taxonomy['Species'][i] = row[1]\n",
    "                    #l.append(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1660"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "source": [
    "len(data_taxonomy['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_taxonomy_df = pd.DataFrame(data_taxonomy) \n",
    "data_taxonomy_df.to_csv('data_taxonomy_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(data_df['wikipedia_url'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Kingdom      Phylum      Class       Order    Suborder         Family  \\\n",
       "0  Animalia    Chordata   Reptilia    Squamata   Serpentes     Colubridae   \n",
       "1   Plantae        None       None     Rosales        None       Rosaceae   \n",
       "2  Animalia  Arthropoda    Insecta  Orthoptera    Ensifera  Tettigoniidae   \n",
       "3  Animalia  Arthropoda  Arachnida     Araneae        None     Salticidae   \n",
       "4  Animalia    Chordata   Reptilia  Testudines  Cryptodira       Emydidae   \n",
       "\n",
       "        Genus       Species  \n",
       "0    Storeria     S. dekayi  \n",
       "1  Potentilla  P. norvegica  \n",
       "2        None          None  \n",
       "3    Marpissa    M. lineata  \n",
       "4   Terrapene   T. carolina  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Kingdom</th>\n      <th>Phylum</th>\n      <th>Class</th>\n      <th>Order</th>\n      <th>Suborder</th>\n      <th>Family</th>\n      <th>Genus</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Animalia</td>\n      <td>Chordata</td>\n      <td>Reptilia</td>\n      <td>Squamata</td>\n      <td>Serpentes</td>\n      <td>Colubridae</td>\n      <td>Storeria</td>\n      <td>S. dekayi</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Plantae</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Rosales</td>\n      <td>None</td>\n      <td>Rosaceae</td>\n      <td>Potentilla</td>\n      <td>P. norvegica</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Animalia</td>\n      <td>Arthropoda</td>\n      <td>Insecta</td>\n      <td>Orthoptera</td>\n      <td>Ensifera</td>\n      <td>Tettigoniidae</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Animalia</td>\n      <td>Arthropoda</td>\n      <td>Arachnida</td>\n      <td>Araneae</td>\n      <td>None</td>\n      <td>Salticidae</td>\n      <td>Marpissa</td>\n      <td>M. lineata</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Animalia</td>\n      <td>Chordata</td>\n      <td>Reptilia</td>\n      <td>Testudines</td>\n      <td>Cryptodira</td>\n      <td>Emydidae</td>\n      <td>Terrapene</td>\n      <td>T. carolina</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "source": [
    "data_taxonomy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "1. Put dictionary in database\n",
    "    a. Use something like Unstructured database like MongoDB.\n",
    "        * Each record is a dictionary.\n",
    "        \n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd07812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}